{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import socket\n",
    "from PIL import Image\n",
    "from scipy.spatial import distance\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def step(self, end, reward, state):\n",
    "        # return 0 # nothing\n",
    "        # return 1 # left\n",
    "        # return 2 # right\n",
    "        return   3 # random\n",
    "    \n",
    "    \n",
    "    \n",
    "class Environment:\n",
    "    def __init__(self, ip = \"127.0.0.1\", port = 13000, size = 200, timescale = 3):\n",
    "        self.client     = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        self.ip         = ip\n",
    "        self.port       = port\n",
    "        self.size       = size\n",
    "        self.timescale  = timescale\n",
    "\n",
    "        self.client.connect((ip, port))\n",
    "\n",
    "    def reset(self):\n",
    "        self._send(1, 0)\n",
    "        return self._receive()\n",
    "\n",
    "    def step(self, action):\n",
    "        self._send(2, action)\n",
    "        return self._receive()\n",
    "\n",
    "    def state2image(self, state):\n",
    "        return Image.fromarray(np.array(state, \"uint8\").reshape(self.size, self.size, 3))\n",
    "\n",
    "    def _receive(self):\n",
    "        # Kudos to Jan for the socket.MSG_WAITALL fix!\n",
    "        data   = self.client.recv(2 + 3 * self.size ** 2, socket.MSG_WAITALL)\n",
    "        end    = data[0]\n",
    "        reward = data[1]\n",
    "        state  = [data[i] for i in range(2, len(data))]\n",
    "\n",
    "        return end, reward, state\n",
    "\n",
    "    def _send(self, action, command):\n",
    "        self.client.send(bytes([action, command]))\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "class EnvironmentWrapper:   # Wrapper around an environment object\n",
    "    \n",
    "    def __init__(self, env, background = np.array([[0]]), verbose = False, reward_victory = 1, reward_suicide = -10, reward_killed = -1, n_frames = 5):\n",
    "        \n",
    "        # Background: image passed as bckg, the image already loaded, not the dorection of the image in the pc\n",
    "        \n",
    "        self.env = env\n",
    "        self.verbose    = verbose\n",
    "        self.reward_victory = reward_victory\n",
    "        self.reward_suicide = reward_suicide\n",
    "        self.reward_killed = reward_killed\n",
    "        self.n_frames = n_frames               # The amount of final frames it checks to decide it's a victory or suicide\n",
    "                                               # 5 it's a nice selection, as only one could be just ricocheting from the collision\n",
    "        \n",
    "        # When loaded the wrapper, the environment resets\n",
    "        self.env.reset()\n",
    "\n",
    "        # History of behavior \n",
    "        self.history = []       # history of position\n",
    "        self.n_objects = []     # records whether there are 1 or 2 objects in the image\n",
    "        self.size_objects = []  # when there's only one object in the arena records size, \n",
    "                                # two robots are bigger than one\n",
    "        \n",
    "        self.distance = []      # Distance between agents\n",
    "                                # If distance is extremely low, it's most likely due to one of the agents being\n",
    "                                # out of sight from the environment, used to mark likelihood of corner presence\n",
    "        \n",
    "        self.corner = []        # For every frame whether there's an agent on the corner is marker\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Have we a background or not?\n",
    "     \n",
    "        if np.all(background == np.array([[0]])):\n",
    "            if len(glob.glob('background_'+str(env.size)+'.png'))!=0:\n",
    "                self.background = cv2.imread('background_'+str(env.size)+'.png')\n",
    "            else:\n",
    "                self.background = self.automatic_background_segmentation()\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            self.background = background\n",
    "        \n",
    "        \n",
    "        \n",
    "    def step(self, action, get_image = False):\n",
    "        \n",
    "        end, reward, state = env.step(action)\n",
    "        \n",
    "        \n",
    "        # A image of the environment is taken\n",
    "        state = np.array(env.state2image(state))\n",
    "        \n",
    "        # The agents are located in that image\n",
    "        agents = self.agent_enhacement(state)\n",
    "        \n",
    "        # Positions of the agents\n",
    "        pos = self.positions(agents)\n",
    "        \n",
    "        \n",
    "        # If get_image true, parameter of the method, the image\n",
    "        if get_image:\n",
    "            return end, reward, pos, agents\n",
    "    \n",
    "        if end == 1:  # When the environment finishes\n",
    "             \n",
    "            if reward == 10:  # The agent wins\n",
    "                return end, self.reward_victory, state\n",
    "                \n",
    "            # Checks if has commited suicide\n",
    "            if len(np.unique(env_n.n_objects[-5:]))==1 and np.unique(env_n.n_objects[-5:])[0]==0:    \n",
    "                # Here it's checked the amount of agents detected in the last frames is the same in every frame, and it's different to 1 (0 means 2 or higher)                            \n",
    "                return end, self.reward_suicide, state\n",
    "            \n",
    "            else:  # There are not two or more different blobs\n",
    "                if self.corner[-1] == 1:   # If it's because one is in the corner and the agent dies, suicide\n",
    "                    return end, self.reward_suicide, state      \n",
    "                else:   # If the two agents are interacted, it'll be assumed that it was killed\n",
    "                    return end, self.reward_killed, state      \n",
    "                    \n",
    "        return end, reward, state\n",
    "    \n",
    "    \n",
    "    def reset(self, get_image = False):\n",
    "        \n",
    "        end, reward, state = env.reset()\n",
    "        \n",
    "        #state = np.array(env.state2image(state))\n",
    "        #agents = self.agent_enhacement(state)\n",
    "        #plt.imshow(agents)\n",
    "        #pos = self.positions(agents)\n",
    "        \n",
    "        #if get_image:\n",
    "        #    return end, reward, pos, agents\n",
    "        \n",
    "        \n",
    "        self.history = []       # history of position\n",
    "        self.n_objects = []     # records whether there are 1 or 2 objects in the image\n",
    "        self.size_objects = []  # when there's only one object in the arena records size, \n",
    "                                # two robots are bigger than one\n",
    "        \n",
    "        self.distance = []      # Distance between agents\n",
    "                                # If distance is extremely low, it's most likely due to one of the agents being\n",
    "                                # out of sight from the environment, used to mark likelihood of corner presence\n",
    "        \n",
    "        self.corner = []    \n",
    "        \n",
    "        return end, reward, state\n",
    "            \n",
    "        \n",
    "    def automatic_background_segmentation(self):\n",
    "        #Get images\n",
    "        \n",
    "        # Background segmentation, only happens once, the environment automatically performs it the first time\n",
    "        \n",
    "        self.env.reset()\n",
    "        \n",
    "        \n",
    "        # Keep some images, not too much, we just want the agents to move a little\n",
    "        \n",
    "        img_list = []\n",
    "        for i in range(100):\n",
    "            _ =  self.env.step(3)\n",
    "            \n",
    "            # Every 5 images save one of them\n",
    "            if i%5==0:\n",
    "                img_list.append(np.array(self.env.state2image(_[-1])))\n",
    "                \n",
    "            # If the game is endded just finish it\n",
    "            if _[0]==1:\n",
    "                break\n",
    "        self.env.reset()\n",
    "        \n",
    "        # Save the images as numoy arrays\n",
    "        img_list_arr = [np.array(i) for i in img_list]\n",
    "    \n",
    "    \n",
    "        from itertools import product\n",
    "\n",
    "        dim_x, dim_y, n_channels = img_list[0].shape\n",
    "        \n",
    "        # Black canvas of a given dimension\n",
    "        canvas_baseline = np.zeros((dim_x, dim_y, n_channels))\n",
    "    \n",
    "        # Here for each pixel in the canvas, the same pixel is examined in every image, and the most common value\n",
    "        # (the background, as the agents are moving) will be taken\n",
    "        for x,y,c in product([i for i in range(dim_x)],[i for i in range(dim_y)],[i for i in range(n_channels)]):\n",
    "            values, counts = np.unique([i[x,y][c] for i in img_list_arr ], return_counts = True)\n",
    "            canvas_baseline[x,y,c] = values[np.argmax(counts)]\n",
    "\n",
    "        cv2.imwrite('background_'+str(env.size)+'.png', canvas_baseline)\n",
    "        \n",
    "        return canvas_baseline.astype(int)\n",
    "    \n",
    "    \n",
    "    def agent_enhacement(self, img_list):\n",
    "        \n",
    "        if type(img_list)!=list:\n",
    "            img_list_support = []\n",
    "            img_list_support.append(img_list)\n",
    "            img_list = img_list_support\n",
    "            \n",
    "        modified_imgs = []\n",
    "        \n",
    "        \n",
    "        for i in img_list:    \n",
    "            \n",
    "            \n",
    "            # Substract the background from the image\n",
    "            base = np.abs(self.background - np.array(i))\n",
    "\n",
    "            \n",
    "            # The image is put in black and white\n",
    "            gray = cv2.cvtColor(np.uint8(base), cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Get a mask for the agents based on the grey image from the substracted image and background\n",
    "            _, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            # Get the agents cropped from the image\n",
    "            res = cv2.bitwise_and(np.uint8(i),np.uint8(i),mask = np.uint8(thresh))\n",
    "\n",
    "            modified_imgs.append(res)    \n",
    "            \n",
    "            \n",
    "        if len(modified_imgs)==1:\n",
    "            return modified_imgs[0]\n",
    "        \n",
    "        return modified_imgs\n",
    "    \n",
    "    \n",
    "    \n",
    "    def positions(self, image):\n",
    "        \n",
    "        # This function gets the position of the agents\n",
    "        image_original = np.copy(image)\n",
    "    \n",
    "        \n",
    "        \n",
    "        # Grey image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # Only sabe \n",
    "        _, image = cv2.threshold(image,1,255,cv2.THRESH_BINARY)\n",
    "        \n",
    "        \n",
    "        # Do some morphological operations on the agents' blobs\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        image = cv2.dilate(image, kernel, iterations = 3)\n",
    "        image = cv2.erode(image, kernel, iterations = 3)\n",
    "\n",
    "        # this functions gets 2 values on opencv2 and 4, but 3 in opencv3, so it requires opencv3\n",
    "        # The version i used is opencv-python==3.4.8.29\n",
    "        a, contours, c = cv2.findContours(image, cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "        pos = []  # List of positions of the agents\n",
    "        \n",
    "        \n",
    "        #If there are several agents, 2 basically\n",
    "        \n",
    "        if len(contours)>1:\n",
    "            \n",
    "            dict_red_centers = {}\n",
    "            \n",
    "            # For each contour:\n",
    "            for contour in contours:\n",
    "                \n",
    "                #Find a rectangle that contains the whole image for each agent\n",
    "                (x,y,w,h) = cv2.boundingRect(contour)\n",
    "\n",
    "                # Get the values where there are pixels with red value different from 0\n",
    "                red_value = np.where(image_original[y:y+h,x:x+w,0]!=0)\n",
    "                \n",
    "                \n",
    "                agent_crop = image_original[y:y+h,x:x+w,0]\n",
    "\n",
    "                \n",
    "                red_sum = 0\n",
    "                for x_i, y_i in zip(red_value[0], red_value[1]):\n",
    "                    # All values of red are added\n",
    "                    red_sum += int(agent_crop[x_i, y_i])\n",
    "                \n",
    "                # The position is used as key, position of the bounding box saved in the dict\n",
    "                dict_red_centers[red_sum]=(int(x+w/2), int(y+h/2))\n",
    "\n",
    "            # Reder agents get fist, (red value is key in the dict) so it can be sorted\n",
    "            for agent in sorted(dict_red_centers.keys())[::-1]: #red first\n",
    "                pos.append(dict_red_centers[agent])\n",
    "\n",
    "            self.n_objects.append(0)\n",
    "            self.corner.append(0)\n",
    "\n",
    "\n",
    "        # If there's only one blob detected after substracting the background\n",
    "        if len(contours)==1:\n",
    "            \n",
    "            image = image_original\n",
    "            \n",
    "            # What will be done is calculate the 'center' of the red and blue pixels in the blob\n",
    "            \n",
    "            a = np.where(image[:,:,0]!=[0]) # Positions of pixels different from 0 blakc\n",
    "            \n",
    "            self.size_objects.append(len(a[0]))\n",
    "            \n",
    "            values = []\n",
    "            \n",
    "            # Combining the list of x and y positions\n",
    "            for i in zip(a[0], a[1]):\n",
    "                values.append(image[i[0],i[1],0])\n",
    "\n",
    "            \n",
    "            # Only leave the brightest pixels of a given color, red in this case [:,:,0 <---- red channel]\n",
    "            _, img = cv2.threshold(image[:,:,0], values[-int(len(values)/10)], 255, cv2.THRESH_TOZERO)\n",
    "\n",
    "                \n",
    "            # Using moments to calculate the center of the brightest pixels\n",
    "            M = cv2.moments(img)\n",
    "            cX = int((M[\"m10\"]+0.0001) / (M[\"m00\"]+0.0001))\n",
    "            cY = int((M[\"m01\"]+0.0001) / (M[\"m00\"]+0.0001))\n",
    "\n",
    "            red_agent = (cX, cY)\n",
    "\n",
    "            #############\n",
    "\n",
    "            # Same as before but for the other color (blue)\n",
    "            \n",
    "            a = np.where(image[:,:,2]!=[0])\n",
    "            values = []\n",
    "            for i in zip(a[0], a[1]):\n",
    "                values.append(image[i[0],i[1],2])\n",
    "\n",
    "\n",
    "            _, img = cv2.threshold(image[:,:,2], values[-int(len(values)/10)], 255, cv2.THRESH_TOZERO)\n",
    "\n",
    "            M = cv2.moments(img)\n",
    "            cX = int((M[\"m10\"]+0.0001)  / (M[\"m00\"]+0.0001) )  #0.0001 are there to avoid 0/0 divisions\n",
    "            cY = int((M[\"m01\"]+0.0001)  / (M[\"m00\"]+0.0001) )\n",
    "\n",
    "\n",
    "            blue_agent = (cX, cY)\n",
    "\n",
    "            pos = [red_agent, blue_agent] # Saving positions for the agents when together\n",
    "            \n",
    "           \n",
    "            \n",
    "            \n",
    "            self.n_objects.append(1)\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            if self.verbose: print('---------  INTERSECTION -----------')   # Marking the intersection of the \n",
    "        \n",
    "        if len(contours)==0:\n",
    "            pos = [(0,0),(0,0)]\n",
    "                \n",
    "        self.history.append(pos)\n",
    "        if self.verbose: print('positions object,   ', pos)\n",
    "\n",
    "        self.distance.append(distance.euclidean(pos[0], pos[1]))\n",
    "    \n",
    "        ######\n",
    "            \n",
    "        #Checking presence in corners\n",
    "        \n",
    "        # This implies that the object is close to the same, expected if only there's one agent left\n",
    "        if self.distance[-1] <= 1.0:\n",
    "            self.corner.append(1)\n",
    "        \n",
    "        if self.verbose: print(distance.euclidean(pos[0], pos[1]))\n",
    "            \n",
    "        return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment()\n",
    "env_n = EnvironmentWrapper(env, reward_suicide=-100)\n",
    "\n",
    "\n",
    "for i in range(10000):\n",
    "    r = env_n.step(3)\n",
    "  \n",
    "    \n",
    "    \n",
    "    if r[0]!=0:\n",
    "        print(r[:2])\n",
    "        env_n.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
